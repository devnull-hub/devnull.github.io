



























































































































































































































































































































































































































[{"categories":["aws","cloud","cli"],"contents":"Getting Started Amazon Simple Storage Service (Amazon S3) is an cloud based object storage device. It is a low cost storage widely used for the backup or static website content.\nIn this post, we will take a look at how to deploy a website to an S3 bucket using the AWS cli.\nSetup If you haven’t setup the AWS CLI already.\nCheck out the references for all of the commands used.\nS3 Static Website Steps for hosting s3 static website are as followed:\nCreate a new bucket with a unique name Enable public access to the bucket Update the bucket policy for public read access Enable the s3 bucket to host an index and error html page Upload website 1. Create New Bucket aws s3 mb will create a new bucket. Make sure you change unique-bucket-name to something meaningful.\naws s3 mb \u0026#34;s3://unique-bucket-name\u0026#34; List buckets\naws s3 ls 2023-01-24 19:46:02 unique-bucket-name 2. Enable Public Access aws s3api put-public-access-block allows the public access to the bucket. Setting all of the blocks to false to enable public access.\naws s3api put-public-access-block \\ --bucket unique-bucket-name \\ --public-access-block-configuration \u0026#34;BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false\u0026#34; 3. Update Bucket Policy aws s3api put-bucket-policy allows to specify a bucket policy which has to be written in JSON. This policy will allow anyone to get the objects ot of the bucket.\nSee Setting permissions for website access\naws s3api put-bucket-policy --bucket devnall-io --policy file://policy.json policy.json:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2023-01-24\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::unique-bucket-name/*\u0026#34; ] } ] } 4. Enable s3 Bucket to Host aws s3 website configures the bucket as a website. Need to include an index and an error page. We could specify a single page for both of these. This is usually done with a single page application.\naws s3 website \u0026#34;s3://unique-bucket-name\u0026#34; --index-document index.html --error-document index.html 5. Upload Static Website aws s3 sync will update the buckets contents with the contents of the local directory.\naws s3 sync directory-path \u0026#34;s3://unique-bucket-name/\u0026#34; Tip\rJust copy a single file, can be done with aws s3 cp\n# Copy a file to an s3 bucket aws s3 cp path-to-file \u0026#34;s3://unique-bucket-name/filename\u0026#34; # Copy a file from an s3 bucket aws s3 cp \u0026#34;s3://unique-bucket-name/filename\u0026#34; path-to-file s3 vs s3api\ns3api gives complete control of S3 buckets s3 gives a higher level of abstraction for some of the more common operations to perform on an S3 bucket Single Script Bash script running commands we just completed. There are a few more variables to make the region and profile easier to configure.\n#!/bin/bash bucket_name=\u0026#39;unique-bucket-name\u0026#39; website_directory=\u0026#39;/path/to/website/\u0026#39; region=\u0026#39;us-east-1\u0026#39; profile=\u0026#39;default\u0026#39; # 1. Create a new bucket with a unique name aws s3 mb \\ --profile $profile \\ --region $region \\ --region us-east-1 \u0026#34;s3://$bucket_name\u0026#34; # 2. Enable public access to the bucket aws s3api put-public-access-block \\ --profile $profile \\ --region $region \\ --bucket $bucket_name \\ --public-access-block-configuration \u0026#34;BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false\u0026#34; # 3. Update the bucket policy for public read access: aws s3api put-bucket-policy \\ --profile $profile \\ --region $region \\ --bucket $bucket_name \\ --policy \u0026#34;{ \\\u0026#34;Version\\\u0026#34;: \\\u0026#34;2012-10-17\\\u0026#34;, \\\u0026#34;Statement\\\u0026#34;: [ { \\\u0026#34;Sid\\\u0026#34;: \\\u0026#34;PublicReadGetObject\\\u0026#34;, \\\u0026#34;Effect\\\u0026#34;: \\\u0026#34;Allow\\\u0026#34;, \\\u0026#34;Principal\\\u0026#34;: \\\u0026#34;*\\\u0026#34;, \\\u0026#34;Action\\\u0026#34;: \\\u0026#34;s3:GetObject\\\u0026#34;, \\\u0026#34;Resource\\\u0026#34;: \\\u0026#34;arn:aws:s3:::$bucket_name/*\\\u0026#34; } ] }\u0026#34; # 4. Enable the s3 bucket to host an `index` and `error` html page aws s3 website \u0026#34;s3://$bucket_name\u0026#34; \\ --profile $profile \\ --region $region \\ --index-document index.html \\ --error-document index.html # # 5. Upload you website aws s3 sync \\ --profile $profile \\ --region $region \\ $website_directory \u0026#34;s3://$bucket_name/\u0026#34; Once the bucket is created, run the sync code to push new updates:\n#!/bin/bash bucket_name=\u0026#39;unique-bucket-name\u0026#39; website_directory=\u0026#39;/path/to/website/\u0026#39; region=\u0026#39;us-east-1\u0026#39; profile=\u0026#39;default\u0026#39; aws s3 sync \\ --profile $profile \\ --region $region \\ $website_directory \u0026#34;s3://$bucket_name/\u0026#34; Destroy the bucket:\n#!/bin/bash bucket_name=\u0026#39;unique-bucket-name\u0026#39; website_directory=\u0026#39;/path/to/website/\u0026#39; region=\u0026#39;us-east-1\u0026#39; profile=\u0026#39;default\u0026#39; aws s3 rm \\ --profile $profile \\ --region $region \\ --recursive s3://$bucket_name aws s3api delete-bucket \\ --profile $profile \\ --region $region \\ --bucket $bucket_name Summary This post provided you with an overview of setting up a static web site using AWS CLI along with shell scripts to backup website content to the S3 bucket. Hugo will need a little more tweaking in the config.toml with the baseURL = \u0026quot;https://example.com/\u0026quot; to https://unique-bucket-name.s3.us-west-1.amazonaws.com/\nCheck out the something interesting: Getting Started with Hugo Next in the Series: Setup Static Website AWS CLI\r","date":"January 23, 2023","image":"https://devnall.io/images/post/cloud/aws/static-web_hu52c990b2082dd6c9abc995614b8857ba_27110_650x0_resize_box_3.png","permalink":"/blog/cloud/aws/static-web/","title":"Setup Static Website AWS CLI"},{"categories":["appium","python","android","windows"],"contents":"Getting Started In the last post Appium Desktop Inspector – Part 2 we successfully used Appium Desktop Inspector to inspect elements to use for automating Android apps. In this post will cover Python script to finish out this series. This is for demonstration purposes and no error checking or code efficiency is implemented.\nPrerequisites Python 3.8.8 Appium-Python-Client Download the project in the github py-auto-calc-mobile\nSet Appium Python │ README.md │ ├───apps │ Calc.apk │ ├───code │ calc-install.py │ calc.py pip install Appium-Python-Client Include the following libraries\nfrom appium import webdriver from appium.webdriver.common.touch_action import TouchAction from appium.webdriver.common.appiumby import AppiumBy import os import time Setup Desired Capabilities Setup your desired capabilities before running the test. There are two versions of this setup. One assumes calculator already installed and the other will install the app.\nIn the calc.py and calc-install.py file, update the information about platformName, deviceName, app(PATH of your app), appPackage and appActivity.\nAlready installed # Parameters DEVICE_NAME = \u0026#34;My Phone\u0026#34; PLATFORM_VERSION = \u0026#34;11\u0026#34; APP_PACK = \u0026#34;com.google.android.calculator\u0026#34; APP_ACT = \u0026#34;com.android.calculator2.Calculator\u0026#34; desired_cap = { \u0026#34;deviceName\u0026#34;: DEVICE_NAME, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;udid\u0026#34;: \u0026#34;emulator-5554\u0026#34;, \u0026#34;platformVersion\u0026#34;: PLATFORM_VERSION, \u0026#34;automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34;, \u0026#34;appPackage\u0026#34;: APP_PACK, \u0026#34;appActivity\u0026#34;: APP_ACT, \u0026#34;noReset\u0026#34;: \u0026#34;true\u0026#34; } # CONNECT TO APPIUM driver = webdriver.Remote(\u0026#34;http://127.0.0.1:4723/wd/hub\u0026#34;, desired_cap) Install App If app is not installed use calc-install.py then this needs to be include the following to the desired capabilities. \u0026quot;app\u0026quot;: \u0026quot;/paht-to-app/app.apk\u0026quot;,\n# Parameters DEVICE_NAME = \u0026#34;My Phone\u0026#34; PLATFORM_VERSION = \u0026#34;11\u0026#34; # Returns abs path relative to this file and not cwd PATH = lambda p: os.path.abspath( os.path.join(os.path.dirname(__file__), p) ) APP_PATH = PATH( \u0026#34;../apps/Calc.apk\u0026#34; ) print(APP_PATH) # Desired Capabilities desired_cap = { \u0026#34;deviceName\u0026#34;: DEVICE_NAME, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;udid\u0026#34;: \u0026#34;emulator-5554\u0026#34;, \u0026#34;platformVersion\u0026#34;: PLATFORM_VERSION, \u0026#34;automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34;, \u0026#34;app\u0026#34;: APP_PATH, \u0026#34;noReset\u0026#34;: \u0026#34;true\u0026#34; } # CONNECT TO APPIUM driver = webdriver.Remote(\u0026#34;http://127.0.0.1:4723/wd/hub\u0026#34;, desired_cap) Test Case In the last post we pulled the element IDs Appium Desktop Inspector – Part 2\n# Test case to test addition operation ... TRUNCATED OUTPUT ... def test_add_operation(): driver.find_element(AppiumBy.ID, \u0026#34;com.google.android.calculator:id/digit_2\u0026#34;).click() print(\u0026#34;Pressing 2\u0026#34;) driver.find_element(AppiumBy.ID, \u0026#34;com.google.android.calculator:id/op_add\u0026#34;).click() print(\u0026#34;Pressing Plus\u0026#34;) ... TRUNCATED OUTPUT ... Stop the Appium Driver\ndef tearDown(): # Close is not working with appium so I\u0026#39;ve used quit driver.quit() Summary This was a very simple setup to demonstrate application automation with Android and Appium.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 17, 2023","image":"https://devnall.io/images/post/py-calc_huf2938bea3cd568949471fdb1f60ac785_534562_650x0_resize_box_1.gif","permalink":"/blog/devops/python/appium/use-case/","title":"Python Automation Android Calculator"},{"categories":["appium","python","android","windows"],"contents":"Getting Started In the last post Appium Desktop Inspector – Part 1 we successfully launched Appium Desktop Inspector in this post will cover the mobile inspection to gather Object Hierarchy Dump for automating our Python script.\nWe will be using Desktop Inspector to identify the elements in the mobile app\nFind element by ID Find element by ClassName Find element by Tag Name Find element by Accessibility ID Find element by XPath This steps will use Google calculator apk hosted on APKPure\nWarning\rWith APKPure app store you can download Android apps without the Google Play store’s restrictions or Google Mobile Services installed. The Google Mobile Services is installed on this image, but we would highly suggest creating a dev gmail account. Unverified apps can be dangerous, as they can compromise your device and steal your data\u0026hellip; This is for testing purpose only. Download and use at your own risk!s\rDownload Google calculator apk\nChange /path-to-app/ were the download app.\n{ \u0026#34;deviceName\u0026#34;: \u0026#34;My Phone\u0026#34;, \u0026#34;udid\u0026#34;: \u0026#34;emulator-5554\u0026#34;, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;platformVersion\u0026#34;: \u0026#34;11\u0026#34;, \u0026#34;automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34;, \u0026#34;app\u0026#34;: \u0026#34;/path-to-app/Calc.apk\u0026#34;, \u0026#34;noReset\u0026#34;: true } Appium Desktop Inspector Appium Desktop Viewer has 3 panes. Object hierarchy and selected element’s details are displayed in two different panes. Appium Desktop Inspector lets you interact with the mobile app\nOpen Appium Desktop Inspector and launch Google Calculator app.\nAssume that we want run a calculation 2+4=\nThe Selected Element pane would show the details of the element that has just been selected. The pane has 3 buttons at the top – Tap, Send Keys and Clear. All these three buttons can be used to perform actions on the mobile app.\nSelect the number TWO this will be highlighted. Press the Tap\nScreen will start getting refreshed. And after a few seconds, it will show the TWO.\nThis will also appear on the mobile device.\nBoth the accessibility id, id properties and Xpath of the elements are shown.\nAppium Desktop Inspector shows Find By ids at the top\nWe will use the ID for this app com.google.android.calculator:id/digit_2 as the XPath is not recommended in some cases.\nRepeat the steps for all the keys or actions we want to complete.\nThe following Element IDs will be used in our script. You will have to select each element and inspect it.\ncom.google.android.calculator:id/digit_2 com.google.android.calculator:id/op_add com.google.android.calculator:id/digit_4 com.google.android.calculator:id/eq com.google.android.calculator:id/result_final Sometimes we will not get an ID and have to use XPath or other methods like Swipe and Tap at the top of the page.\nTip\rTry different parts of the navigation bar Refresh source screen is useful and Quit Session.\nThe most useful tool on the navigation bar is the Record.\nThis can give you hints to the code used for different languages. We are focused on python and will look at this.\nBasic Code Snippet\nText Output:\nel4 = driver.find_element_by_accessibility_id(\u0026#34;2\u0026#34;) el4.click() el5 = driver.find_element_by_accessibility_id(\u0026#34;plus\u0026#34;) el5.click() el6 = driver.find_element_by_accessibility_id(\u0026#34;4\u0026#34;) el6.click() el7 = driver.find_element_by_accessibility_id(\u0026#34;equals\u0026#34;) el7.click() Select the Boilerplate Code\n# This sample code uses the Appium python client # pip install Appium-Python-Client # Then you can paste this into a file and simply run with Python from appium import webdriver caps = {} caps[\u0026#34;deviceName\u0026#34;] = \u0026#34;My Phone\u0026#34; caps[\u0026#34;udid\u0026#34;] = \u0026#34;emulator-5554\u0026#34; caps[\u0026#34;platformName\u0026#34;] = \u0026#34;Android\u0026#34; caps[\u0026#34;platformVersion\u0026#34;] = \u0026#34;11\u0026#34; caps[\u0026#34;automationName\u0026#34;] = \u0026#34;UiAutomator2\u0026#34; caps[\u0026#34;app\u0026#34;] = \u0026#34;/path-to/app/Calc.apk\u0026#34; caps[\u0026#34;noReset\u0026#34;] = True caps[\u0026#34;ensureWebviewsHavePages\u0026#34;] = True driver = webdriver.Remote(\u0026#34;http://localhost:4723/wd/hub\u0026#34;, caps) el4 = driver.find_element_by_accessibility_id(\u0026#34;2\u0026#34;) el4.click() el5 = driver.find_element_by_accessibility_id(\u0026#34;plus\u0026#34;) el5.click() el6 = driver.find_element_by_accessibility_id(\u0026#34;4\u0026#34;) el6.click() el7 = driver.find_element_by_accessibility_id(\u0026#34;equals\u0026#34;) el7.click() driver.quit() Note\rThe find_element_by_accessibility_id is no no longer used, so this will not work in this instance, but gets the general outline of the code and is good start. This is an older version of Appium and not sure if this is updated in newer version.\rSummary This was all about identifying elements on your mobile app using Appium Desktop Inspector. Next we will use Python to code the calculation steps.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 16, 2023","image":"https://devnall.io/images/post/appium_hue7c9a2134d61c3dedaf30871391934c7_769528_650x0_resize_box_3.png","permalink":"/blog/devops/python/appium/inspector-pt2/","title":"Appium Desktop Inspector – Part 2"},{"categories":["appium","python","android","windows"],"contents":"Getting Started Launch Android Studio run Virtual Device Manager\nCreate Device if one already does not exist.\nChoose Hardware\nChoose System Android Image Version\nRun Pixel 4 API 30 image\nEmulator Window\nNow we can interact with virtual device\nadb devices List of devices attached emulator-5554 device Start Appium Server Launch Appium Server and keep defaults\nAppium Desired Capabilities Screen Click on Start Inspector Session button (the first button with search icon) from Appium logs screen\nA new Appium window will be displayed. Have a look at each of the four tabs in this window. When you select any of these tabs, then only the top section of the window changes. The bottom section, starting at Desired Capabilities stays the same way. We will only cover the Automatic Serve\nProvide Desired Capability details for Automatic Server With Appium Desktop Inspector, need to provide all the Desired Capabilities to launch app test case.\nFirst capability, type deviceName in Name field and My Phone in Value field. JSON Representation block shows the capability have been added.\nClick on the + icon, so that a new blank row gets displayed\nAdd the second capability (udid and the device id)\nDevice ID can be found with adb devices command example device id emulator-5554\nadb devices List of devices attached emulator-5554 device Keep on adding new rows till you add all the capabilities or just use the completed JSON file below.\nJSON file to launch Chrome\n{ \u0026#34;deviceName\u0026#34;: \u0026#34;My Phone\u0026#34;, \u0026#34;udid\u0026#34;: \u0026#34;emulator-5554\u0026#34;, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;platformVersion\u0026#34;: \u0026#34;11\u0026#34;, \u0026#34;automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34;, \u0026#34;appPackage\u0026#34;: \u0026#34;com.android.chrome\u0026#34;, \u0026#34;appActivity\u0026#34;: \u0026#34;com.google.android.apps.chrome.Main\u0026#34;, \u0026#34;noReset\u0026#34;: true } Change according to the Desired Capabilities\u0026hellip;.\nWe can use existing applications or install applications with these capabilities.\nInstall appliance just remove appPackage and appActivity and replace with \u0026quot;app\u0026quot;: \u0026quot;/paht-to-app/app.apk\u0026quot;,\nTo retrive appPackage and appActivity first launch application on device in this case Chrome. Connect to the device with adb shell and run dumpsys window displays.\nNote\rAndroid 9 and earlier command dumpsys window windows, but in Android 10 \u0026gt; has been changed to dumpsys window displays\radb shell dumpsys window displays | grep -E \u0026#39;mCurrentFocus\u0026#39; mCurrentFocus=Window{e262ba6 u0 com.android.chrome/com.google.android.apps.chrome.Main} Copy com.android.chrome/com.google.android.apps.chrome.Main as followed\n\u0026#34;appPackage\u0026#34;: \u0026#34;com.android.chrome\u0026#34;, \u0026#34;appActivity\u0026#34;: \u0026#34;com.google.android.apps.chrome.Main\u0026#34;, Start Appium Desktop Inspector Start Appium Desktop Inspector, click on Start Session button from the Desired Capabilities tab.\nAppium window will display the screenshot of Chrome app together with its Object Hierarchy Dump. Allong with Chrome being opened on the device.\nSummary We have now successfully opened Appium Desktop Inspector and this is where we will end this post. Next post will cover the mobile inspection, where we will learn about the different ways to identify mobile elements from Appium Desktop Inspector.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 16, 2023","image":"https://devnall.io/images/post/android-bg_hu82c25fa98cd4e9a8103220017be4b8cb_637869_650x0_resize_q90_box.jpg","permalink":"/blog/devops/python/appium/inspector-pt1/","title":"Appium Desktop Inspector – Part 1"},{"categories":["appium","python","android","windows"],"contents":"Installing Android Studio \u0026amp; Android SDKs for Windows This installation is based Android Studio Dolphin.\nAndroid Studio is the official IDE (Integrated Development Environment) for Android app development and it is based on JetBrains’ IntelliJ IDEA software.\nMinimum system requirements: OS: Windows 8/8.1/10/11 (64-bit) CPU: 2nd generation Intel CPU (Sandy Bridge) or newer, AMD CPU with support for a Windows Hypervisor Memory: 8 GB RAM Free storage: 8 GB Screen resolution: 1280 x 800 Installation Steps Download Android Studio Click Download Android Studio Button\nClick on the “I have read and agree with the above terms and conditions” checkbox followed by the download button\nClick on the Save file button in the appeared prompt box and the file will start downloading.\nOpen the file from downloads and run it. It will prompt the following dialog box.\nChoose Components. Click on next.\nThe prompt will ask for installation path. Choose a path and hit next.\nChoose Start Menu options.\nInstallation will start\nOnce “Finish” is clicked, it will ask whether the previous settings need to be imported [if the android studio had been installed earlier], or not. It is better to choose the ‘Don’t import Settings option’.\nThe finding the available SDK components will run and take awhile.\nAfter it has found the SDK components, it will redirect to the Welcome dialog box.\nChoose Standard and click on Next. Now choose the theme, whether the Light theme or the Dark one. The light one is called the IntelliJ theme whereas the dark theme is called Dracula. Choose as required.\nChoose Standard and click on Next. Now choose the theme, whether the Light theme or the Dark one. The light one is called the IntelliJ theme whereas the dark theme is called Dracula. Choose as required.\nClick on the Next button\nDownload the SDK components.\nClick on Finish. Components begin to download let it complete.\nThe Android Studio has been successfully configured. Now it’s time to launch and build apps. Click on the Finish button to launch it.\nClick on Start a new Android Studio project to build a new app.\nDracula Theme:\nSummary This post was just a quick installation overview. Next post will be writing a simple test case. With Appium and Python.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 14, 2023","image":"https://devnall.io/images/post/as2021.3.1_hu5209bfc76d8f9ecd6b260e234e0f5757_114464_650x0_resize_box_3.png","permalink":"/blog/android/sdk/","title":"Android Studio \u0026 Android SDKs"},{"categories":["appium","python","android","windows"],"contents":"Setup Appium \u0026amp; Android Studio Windows Every app needs to be tested if they get updated frequently these use cases should be automated.\nIn this post we will be covering Appium and Android Studio with Python to automate application testing.\nAppium — is an open source test automation framework for use with native, hybrid and mobile apps. It drives IOS, Android, and Windows apps using the Webdriver protocol. It automates any mobile application from any languages like Ruby, Python, Java, JavaScript, PHP, C# and any test framework, with full access to back-end APIs and DBs.\nAndroid Studio — is the official IDE for Google’s Android OS, built on JetBrains’ designed specifically for Android development, it can also be used in performing automation tests.\nPrerequisites Appium v1.20.2-4 Java JDK Android Studio Dolphin 2021.3.1 Python 3.8.8 Note\r❗❗ v1.20.2-4 is no longer maintained since it is not compatible with Appium 2.0+. Appium Inspector and Appium to inspect elements for Appium 2.0. Node \u0026amp; NPM (Optional) included with Appium Desktop\rInstall Appium Desktop Appium can be installed by command line or with desktop application.\nThis post will focus on the desktop application.\nSteps to install Appium desktop app:\nDownload appium desktop from github page Appium v1.20.2-4 Click on the required file depending for Windows operating system Then double click the .exe and follow all the installation steps Appium Setup window as displayed below\nOnce installation is complete, you will see the below Appium Desktop window\nLeave the Run Appium checkbox selected and click on Finish button. Appium Desktop Start screen will be displayed\nClick on Start Server button. This would start the Appium server and you would see The server is running message in Appium window\nMake sure Java environment is configured. The following post will walk you through these steps:\nSet JAVA_HOME environment variable on Windows 10 Set JAVA_HOME environment variable on Windows 10\nSummary The next post will cover Installing Android Studio \u0026amp; Android SDKs along with writing a simple test case. Also view setting JAVA_HOME environment variable on Windows 10 as this will be needed for Installing Android Studio \u0026amp; Android SDKs.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 13, 2023","image":"https://devnall.io/images/post/android-bg_hu82c25fa98cd4e9a8103220017be4b8cb_637869_650x0_resize_q90_box.jpg","permalink":"/blog/devops/python/appium/setup/","title":"Mobile App Automation"},{"categories":["appium","python","android","windows"],"contents":"Java Setup Install JDK and set JAVA_HOME Download the Java Development Kit (JDK)\nThen double click the JDK and follow all the installation steps.\nTo set JAVA_HOME on a Windows 10:\nTested with:\nWindows 10 JDK 1.9 JAVA_HOME is the name of an environment variable on the operating system that points to the installation directory of JDK (Java Development Kit) or JRE (Java Runtime Environment).\nExample:\nJAVA_HOME = C:\\Program Files\\Java\\jdk-19 Identify the Java home directory, which is generally under C:\\Program Files\\Java directory. Advanced System Settings Open the System Environment Variables dialog by typing environment in the search area on Start menu\nClick the button Environment Variables\nCreate the JAVA_HOME environment variable by clicking the New button at the bottom.\nIn the New System Variable form, enter the name and value as follows:\nJAVA_HOME C:\\Program Files\\Java\\jdk-19 Click OK, and you will see the JAVA_HOME variable is added to the list.\nUpdate the PATH system variable. In the Environment Variables dialog, select the Path variable and click Edit:\nThen in the Edit environment variable dialog, double click on the empty row just below the last text line, and enter %JAVA_HOME%\\bin as follows:\nThe percent signs tell Windows that it refers to a variable JAVA_HOME, and the \\bin specifies the location of java.exe and javac.exe programs which are used to run and compile Java programs, as well as other tools in the JDK. Click OK button to close all the dialogs. Now open application to verify. Or open a command prompt and type the following:\njava -version java version \u0026#34;19.0.1\u0026#34; 2022-10-18 Java(TM) SE Runtime Environment (build 19.0.1+10-21) Java HotSpot(TM) 64-Bit Server VM (build 19.0.1+10-21, mixed mode, sharing) javac -version javac 19.0.1 Summary You can add the path to the bin directory of Java home directly into the PATH variable, but it is recommend to follow the above steps to setup a JAVA_HOME variable because many Java programs depend on it. When you installed a JDK, this might not need to update the system variable because the installer already did it.\nNext in the Series: Mobile App Automation\rSet JAVA_HOME environment variable on Windows 10\rAndroid Studio \u0026amp; Android SDKs\rAppium Desktop Inspector – Part 1\rAppium Desktop Inspector – Part 2\rPython Automation Android Calculator\r","date":"January 13, 2023","image":"https://devnall.io/images/post/java-cup_hu9c3c482075fe63332f3c7acccab731a4_569665_650x0_resize_q90_box.jpg","permalink":"/blog/devops/java-setup/","title":"Set JAVA_HOME environment variable on Windows 10"},{"categories":["docker","devops","linux"],"contents":"Use IPvlan networks IPvlan driver gives control over both IPv4 and IPv6 addressing. The VLAN driver gives administrators control of layer 2 VLAN tagging and even IPvlan L3 routing for use of direct network integration.\nNote\rIPvlan does not assign unique MAC addresses to created sub-interfaces. All the sub-interfaces share parent’s interface MAC address by using unique IP addresses.\rPrerequisites The examples on this post are all single host All examples can be performed on a single host running Docker. Any example using a sub-interface like eth0.10 can be replaced with eth0 or any other valid parent interface on the Docker host. Sub-interfaces with a . are created on the fly. -o parent interfaces can also be left out of the docker network create all together and the driver will create a dummy interface that will enable local host connectivity to perform the examples. Kernel requirements: To check your current kernel version, use uname -r IPvlan Linux kernel v4.2+ (support for earlier kernels exists but is buggy) IPvlan L2 mode example usage An example of the IPvlan L2 mode topology is shown in the following. The driver is specified with -d driver_name option. In this case -d ipvlan.\nSimple IPvlan L2 Mode Example\nThe parent interface in the next example -o parent=eth0 is configured as follows:\nip addr show eth0 3: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 inet 192.168.1.10/24 brd 192.168.1.255 scope global eth0 Use the network from the host’s interface as the --subnet in the docker network create. The container will be attached to the same network as the host interface as set via the -o parent= option.\nCreate the IPvlan network and run a container attaching to it:\nInfo\rIPvlan (-o ipvlan_mode= Defaults to L2 mode if not specified)\rdocker network create -d ipvlan \\ --subnet=192.168.1.0/24 \\ --gateway=192.168.1.1 \\ -o ipvlan_mode=l2 \\ -o parent=eth0 db_net Start a container on the db_net network docker run --net=db_net -it --rm alpine /bin/sh Note\rThe containers can NOT ping the underlying host interfaces as they are intentionally filtered by Linux for additional isolation.\rDocker Compose Example Making things a bit easier with a docker compose file. To illustrate the above, we will use a two Docker Containers.\nWarning\rAll examples were executed in a linux distribution with Docker IPvlan. If you execute them in macOS or Windows environments the sample commands might change a bit.\rThe gateway can be only specified under version 2.\nNote\rAdditional IPAM configurations, such as gateway, are only honored for version 2 at the moment.\rDefault network gateway value for docker-compose version 3\nCreate the docker-compose.yml file:\nversion: \u0026#39;2\u0026#39; services: container1: image: alpine container_name: container1 restart: unless-stopped tty: true networks: - db_net container2: image: alpine container_name: container2 tty: true networks: - db_net networks: db_net: driver: ipvlan driver_opts: ipvlan_mode: l2 parent: eth0 ipam: config: - subnet: 192.168.1.0/24 gateway: 192.168.1.1 From within the directory Run: docker-compose up -d\nValidate Containers Up Showing command and output in the code samples.\nUsing Docker Inspect Check the container process to see if two containers are up and running:\ndocker ps --format \\ \u0026#34;table {{.ID}}\\t{{.Status}}\\t{{.Names}}\u0026#34; CONTAINER ID STATUS NAMES 58129dfe9dda Up 3 minutes container2 39ad7928071a Up 3 minutes container1 Check Docker networks:\ndocker network ls NETWORK ID NAME DRIVER SCOPE 2d44dd74beb6 bridge bridge local bd777dfcc50c host host local 2a2a001fdf18 ipvlan_db_net ipvlan local 156a09c3d2f5 none null local How to Get A Docker Container IP Address:\nUsing Docker Inspect on container ID 39ad7928071a\ndocker inspect -f \u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; 192.168.1.12 Using the Network ID 2a2a001fdf18\ndocker network inspect -f \\ \u0026#39;{{range .IPAM.Config}}{{.Subnet}}{{end}}\u0026#39; 2a2a001fdf18 192.168.1.0/24 Look up each Container\u0026rsquo;s IP individually:\nBased on the ipvlan_db_net Network ID 2a2a001fdf18 assuming jq is instaled.\ndocker network inspect -f \\ \u0026#39;{{json .Containers}}\u0026#39; 2a2a001fdf18 | \\ jq \u0026#39;.[] | .Name + \u0026#34;:\u0026#34; + .IPv4Address\u0026#39; \u0026#34;container1:192.168.1.12/24\u0026#34; \u0026#34;container2:192.168.1.13/24\u0026#34; Using Docker exec In the following example we will work with container1.\nUsing the exec to run commands in a running container, but can execute an interactive sh shell on the container if want to execute additional commands.\ndocker exec -it container1 sh From Docker host ping remote server.\ndocker exec container1 ping 192.168.1.20 Remote host capture packets tcpdump\ntcpdump -e -ni eth0 icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes ... TRUNCATED OUTPUT ... 15:39:26.006311 00:00:00:00:01:10 \u0026gt; 00:00:00:00:01:20, ethertype IPv4 (0x0800), length 98: 192.168.1.12 \u0026gt; 192.168.1.20: ICMP echo request, id 19, seq 4, length 64 15:39:26.006427 00:00:00:00:01:20 \u0026gt; 00:00:00:00:01:10, ethertype IPv4 (0x0800), length 98: 192.168.1.20 \u0026gt; 192.168.1.12: ICMP echo reply, id 19, seq 4, length 64 ... TRUNCATED OUTPUT ... Info\rThe MAC address are the same in the container and host linux system.\rMAC from container: HWaddr 00:00:00:00:01:10\ndocker exec container1 ifconfig eth0 Link encap:Ethernet HWaddr 00:00:00:00:01:10 inet addr:192.168.1.12 Bcast:192.168.1.255 Mask:255.255.255.0 ... TRUNCATED OUTPUT ... MAC from host: ether 00:00:00:00:01:10\nifconfig eth0 eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 192.168.1.10 netmask 255.255.255.0 broadcast 192.168.1.255 ether 00:00:00:00:01:10 txqueuelen 1000 (Ethernet) ... TRUNCATED OUTPUT ... Stop Containers Remove containers and network with docker-compose down\nSummary The VLAN driver builds on top of that in giving administrator complete control of layer 2 VLAN tagging and even IPvlan L3 routing for users interested in underlay network integration.\nBelow are some considerations when using IPvlan:\nPARAMETER IPvlan Network Interface Compatibility Limited Mac Address Hardware Performance Hardware Performance Security Unknown Implementation Needs Advanced Router Configuration Next in the Series: Docker MacVLAN Networks\rDocker Networking Overview\rDocker IPvlan Networks\r","date":"January 7, 2023","image":"https://devnall.io/images/post/devops/docker/container-ship_hu14651a36f9edc6a1d42e5c992de91d16_202595_650x0_resize_q90_box.jpg","permalink":"/blog/devops/docker/networking/ipvlan/","title":"Docker IPvlan Networks"},{"categories":["docker","devops","linux"],"contents":"Docker Networking Overview In this post defines some basic Docker networking concepts.\nNetwork drivers Docker’s networking subsystem is pluggable, using drivers. Several drivers exist by default, and provide core networking functionality:\nbridge: The default network driver. Bridge networks used when applications run in standalone containers that need to communicate.\nhost: For standalone containers, remove network isolation between the container and the Docker host, and use the host’s networking directly.\noverlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. Use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. This strategy removes the need to do OS-level routing between these containers.\nipvlan: IPvlan networks gives total control over both IPv4 and IPv6 addressing. The VLAN driver builds on top of that in giving administrator complete control of layer 2 VLAN tagging and even IPvlan L3 routing for users interested in underlay network integration.\nmacvlan: Macvlan networks allow to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host’s network stack.\nnone: For this container, disable all networking. Usually used in conjunction with a custom network driver. none is not available for swarm services.\nNetwork plugins: You can install and use third-party network plugins with Docker. These plugins are available from Docker Hub or from third-party vendors. See the vendor’s documentation for installing and using a given network plugin.\nNetwork driver summary User-defined bridge networks are best used when need multiple containers to communicate on the same Docker host. Host networks are best when the network stack should not be isolated from the Docker host, but need other aspects of the container to be isolated. Overlay networks are best when you need containers running on different Docker hosts to communicate, or when multiple applications work together using swarm services. Macvlan networks are best when you are migrating from a VM setup or need your containers to look like physical hosts on your network, each with a unique MAC address. Third-party network plugins allow you to integrate Docker with specialized network stacks. Summary Just a short overview of Docker Networking. Future post will include\nDocker MacVLAN Networks\rDocker Networking Overview\rDocker IPvlan Networks\rReferences Docker network understanding-docker-networking-drivers-use-cases ","date":"January 7, 2023","image":"https://devnall.io/images/post/devops/docker/container-ship_hu14651a36f9edc6a1d42e5c992de91d16_202595_650x0_resize_q90_box.jpg","permalink":"/blog/devops/docker/networking/overview/","title":"Docker Networking Overview"},{"categories":["docker","devops","linux"],"contents":"MacVLAN MacVLAN configures a sub-interfaces (also known as slave devices) of a parent physical Ethernet interface with its own unique MAC address and as a result with its own IP address. Applications, Virtual Machines and containers can now be grouped to a specific sub-interface, in order to connect directly to the physical network using their own MAC and IP Address.\nNote\rMacVLAN in the image that mavvlan created unique MAC addresses to sub-interfaces. These can also be manually assigned.\rInfo\rMost NICs have a limitation on the number of MAC addresses. Sometimes exceeding that specific limit may affect the system’s performance. According to IEEE 802.11 protocol specifications, multiple MAC addresses on a single client are not allowed. Macvlan sub-interfaces will be blocked by the user’s wireless interface driver or AP. Use MacVLAN networks Legacy applications or applications which monitor network traffic, expect to be directly connected to the physical network. In this type of situation, use the macvlan network driver to assign a MAC address to each container’s virtual network interface, making it appear to be a physical network interface directly connected to the physical network. Need to designate a physical interface on your Docker host to use for the macvlan, as well as the subnet and gateway of the macvlan. Isolate macvlan networks using different physical network interfaces. Keep the following things in mind:\nIt is very easy to unintentionally damage network due to IP address exhaustion or to “VLAN spread”, which is a situation in which having an large number of unique MAC addresses in the network.\nNetworking equipment needs to be able to handle “promiscuous mode”, where one physical interface can be assigned multiple MAC addresses.\nIf application can work using a bridge on a single Docker host or overlay to communicate across multiple Docker hosts, these solutions may be better.\nCreate a MacVLAN network When creating a macvlan network, it can either be in bridge mode or 802.1q trunk bridge mode.\nIn bridge mode, macvlan traffic goes through a physical device on the host.\nIn 802.1q trunk bridge mode, traffic goes through an 802.1q sub-interface which Docker creates on the fly. This allows to control routing and filtering at a more granular.\nBridge mode To create a macvlan network which bridges with a given physical network interface, use --driver macvlan with the docker network create command. Need to specify the parent, which is the interface the traffic will physically go through on the Docker host.\ndocker network create -d macvlan \\ --subnet=172.16.86.0/24 \\ --gateway=172.16.86.1 \\ -o parent=eth0 pub_net Need to exclude IP addresses from being used in the macvlan network, such as when a given IP address is already in use, use --aux-addresses:\ndocker network create -d macvlan \\ --subnet=192.168.32.0/24 \\ --ip-range=192.168.32.128/25 \\ --gateway=192.168.32.254 \\ --aux-address=\u0026#34;my-router=192.168.32.129\u0026#34; \\ -o parent=eth0 macnet32 802.1q trunk bridge mode If specify a parent interface name with a dot included, such as eth0.50, Docker interprets that as a sub-interface of eth0 and creates the sub-interface automatically.\ndocker network create -d macvlan \\ --subnet=192.168.50.0/24 \\ --gateway=192.168.50.1 \\ -o parent=eth0.50 macvlan50 Use an ipvlan instead of MacVLAN Docker IPvlan Networks This post shows the use of Docker IPvlan networks.\nIn the above example, still using a L3 bridge. Use ipvlan instead, and get an L2 bridge. Specify -o ipvlan_mode=l2.\ndocker network create -d ipvlan \\ --subnet=192.168.210.0/24 \\ --subnet=192.168.212.0/24 \\ --gateway=192.168.210.254 \\ --gateway=192.168.212.254 \\ -o ipvlan_mode=l2 -o parent=eth0 ipvlan210 Use IPv6 If configured the Docker daemon to allow IPv6, use dual-stack IPv4/IPv6 macvlan networks.\ndocker network create -d macvlan \\ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \\ --gateway=192.168.216.1 --gateway=192.168.218.1 \\ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \\ -o parent=eth0.218 \\ -o macvlan_mode=bridge macvlan216 Docker Compose Example Making things a bit easier with a docker compose file. To illustrate the above, we will use a two Docker Containers.\nWarning\rAll examples were executed in a linux distribution with Docker MacVLAN. If you execute them in macOS or Windows environments the sample commands might change a bit.\rThe gateway can be only specified under version 2.\nNote\rAdditional IPAM configurations, such as gateway, are only honored for version 2 at the moment.\rDefault network gateway value for docker-compose version 3\nCreate the docker-compose.yml file:\nversion: \u0026#39;2\u0026#39; services: container1: image: alpine container_name: container1 restart: unless-stopped tty: true networks: - db_net container2: image: alpine container_name: container2 tty: true networks: - db_net networks: db_net: driver: macvlan driver_opts: parent: eth0 ipam: config: - subnet: 192.168.0.0/24 gateway: 192.168.0.1 From within the directory Run: docker-compose up -d\nValidate Containers Up Showing command and output in the code samples.\nUsing Docker Inspect Check the container process to see if two containers are up and running:\ndocker ps --format \\ \u0026gt; \u0026#34;table {{.ID}}\\t{{.Status}}\\t{{.Names}}\u0026#34; CONTAINER ID STATUS NAMES 66c84b6688d6 Up About a minute container1 ea6b160c7d6e Up About a minute container2 Check Docker networks:\ndocker network ls NETWORK ID NAME DRIVER SCOPE 2d44dd74beb6 bridge bridge local bd777dfcc50c host host local fcf63e3315dc macvlan_db_net macvlan local 156a09c3d2f5 none null local How to Get A Docker Container IP Address:\nUsing Docker Inspect on container ID 39ad7928071a\ndocker inspect -f \u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; 192.168.1.12 Using the Network ID fcf63e3315dc\ndocker network inspect -f \\ \u0026#39;{{range .IPAM.Config}}{{.Subnet}}{{end}}\u0026#39; fcf63e3315dc 192.168.1.0/24 Look up each Container\u0026rsquo;s IP individually:\nBased on the ipvlan_db_net Network ID fcf63e3315dc assuming jq is instaled.\ndocker network inspect -f \\ \u0026#39;{{json .Containers}}\u0026#39; fcf63e3315dc | \\ jq \u0026#39;.[] | .Name + \u0026#34;:\u0026#34; + .IPv4Address\u0026#39; \u0026#34;container1:192.168.1.12/24\u0026#34; \u0026#34;container2:192.168.1.13/24\u0026#34; Look up each Container\u0026rsquo;s MAC individually:\ndocker network inspect -f \\ \u0026#39;{{json .Containers}}\u0026#39; fcf63e3315dc | \\ jq \u0026#39;.[] | .Name + \u0026#34;:\u0026#34; + .MacAddress\u0026#39; \u0026#34;container1:02:42:c0:a8:00:02\u0026#34; \u0026#34;container2:02:42:c0:a8:00:03\u0026#34; Using Docker exec In the following example we will work with container1.\nUsing the exec to run commands in a running container, but can execute an interactive sh shell on the container if want to execute additional commands.\ndocker exec -it container1 sh From Docker host ping remote server.\ndocker exec container1 ping 192.168.1.20 Remote host capture packets tcpdump\ntcpdump -e -ni eth0 icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes ... TRUNCATED OUTPUT ... 03:36:24.792270 02:42:c0:a8:00:02 \u0026gt; 00:00:00:00:01:10, ethertype IPv4 (0x0800), length 98: 192.168.1.12 \u0026gt; 192.168.1.20: ICMP echo request, id 8, seq 0, length 64 03:36:24.792391 00:00:00:00:01:10 \u0026gt; 02:42:c0:a8:00:02, ethertype IPv4 (0x0800), length 98: 192.168.1.20 \u0026gt; 192.168.1.12: ICMP echo reply, id 8, seq 0, length 64 MAC from container: HWaddr 02:42:c0:a8:00:02\ndocker exec container1 ifconfig eth0 Link encap:Ethernet HWaddr 02:42:c0:a8:00:02 inet addr:192.168.1.12 Bcast:192.168.1.255 Mask:255.255.255.0 ... TRUNCATED OUTPUT ... MAC from host: ether 00:00:00:00:01:10\nifconfig eth0 eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 192.168.1.10 netmask 255.255.255.0 broadcast 192.168.1.255 ether 00:00:00:00:01:10 txqueuelen 1000 (Ethernet) ... TRUNCATED OUTPUT ... Assiging your own MAC address with the following mac_address: 00:00:00:00:01:11\n... TRUNCATED OUTPUT ... container1: image: alpine container_name: container1 restart: unless-stopped tty: true mac_address: 00:00:00:00:01:11 networks: - db_net ... TRUNCATED OUTPUT ... Stop Containers Remove containers and network with docker-compose down\nSummary This is a great way for legacy applications or applications which monitor network traffic, expect to be directly connected to the physical network.\nBelow are some considerations when using MacVLAN:\nPARAMETER MacVLAN Network Interface Compatibility Common DHCP Server Hardware Performance Low CPU, Normal Network Utilization Security Meets 802.11 standards Implementation Easy to Set-Up Next in the Series: Docker MacVLAN Networks\rDocker Networking Overview\rDocker IPvlan Networks\r","date":"January 6, 2023","image":"https://devnall.io/images/post/devops/docker/container-ship_hu14651a36f9edc6a1d42e5c992de91d16_202595_650x0_resize_q90_box.jpg","permalink":"/blog/devops/docker/networking/macvlan/","title":"Docker MacVLAN Networks"},{"categories":["vcode"],"contents":"VS-Code Folder Templates Because creating the same directories over and over again is annoying to do manually.- Huuums\nAutomation\u0026hellip;automation!!! We are always trying to improve things through automation. Let\u0026rsquo;s not stop with infrastructure and home automation. How about little tasks like creating repeatable templates for these blog posts.\nThis is my new favorite VScode extension for automating redundant tasks when not doing hobby projects that involve video and photograph this tool reminds me of the Digital Rebellion Posthaste, but for media.\nOrganize your projects with customizable templates - Digital Rebellion\nYes we could write a script to stick to the coder\u0026rsquo;s \u0026ldquo;code\u0026rdquo;????\nIntroduction Here comes the VS-Code Folder Templates extension to the rescue.\nCreate reusable files for everyday workflow. Need to focus on standards and patterns that are required to implement reusable files and folders.\nSome of these may include:\nREADME.md index.html hackme.js custom.scss Since we are blogging with Hugo lets use a simple file and directory setup:\n├───post\r│ │ index.md\r│ │\r│ └───images In the root of the project folder create .fttemplates within that directory create blog add index.md and images folder.\n. ├───.fttemplates │ ├───blog │ │ │ index.md │ │ └───images Example\rCreating a post with the following: // blog -\u0026gt; index.md\n# [FTName]\r## Description\r## Installation\r## Usage [FTName] will substitute anything executed when right clicking on folder to run template against.\nSelect template to use\nName: hacker-ninja-blog\n. └───hacker-ninja-blog │ index.md │ └───images Mixing it up a bit with front matter data.\nTemplate Input:\n--- title: \u0026#34;[FTName]\u0026#34; description: \u0026#34;\u0026#34; image: \u0026#34;images/post/placeholder.png\u0026#34; ... TRUNCATED OUTPUT ... --- Output:\n--- title: \u0026#34;hacker-ninja-blog\u0026#34; description: \u0026#34;\u0026#34; image: \u0026#34;images/post/placeholder.png\u0026#34; ... TRUNCATED OUTPUT ... --- The [FTName] also applies to filenames assuming have a css file:\n// template-folder-name -\u0026gt; [FTName].css .[FTName] { } This would create a file named hacker-ninja-blog.css with the following template.\n.[hacker-ninja-blog] { } Summary This is quick introduction to the VS-Code Folder Templates and there a lot moe configuration options that I am still learning check out the git repo vscode-fast-folder-structure.\n","date":"January 2, 2023","image":"https://devnall.io/images/post/folder-wesley-tingey-snNHKZ-mGfE-unsplash_hu966511966371066b361761d79a3a00cf_4930255_650x0_resize_q90_box.jpg","permalink":"/blog/vscode/folder-temp/","title":"VScode Automating Creation Folder and Files"},{"categories":["hugo"],"contents":"\nThe following should generally work, but using .webp format for image and LinedIn at the time of this writing does not support this format. See Media File Types Supported on LinkedIn\nDoing inline markdown image links does no work for regular post, but will not work with LinkedIn v2 share api.\nImages should appear and can be confirmed with LinkedIn\u0026rsquo;s Post Inspector:\nSteps:\nVisit https://www.linkedin.com/post-inspector/ Enter URL and click on Inspect, should see the updated preview image Now try sharing your URL on LinkedIn Share on LinkedIn Image Metadata If you would like people to be able to share site\u0026rsquo;s content on LinkedIn, the source code on your site needs to comply Open Graph Protocol (OGP).\nThis feature built in Hugo’s Open Graph template\nfront-matter Going to configure front-matter variables on individual pages.\nExample with content/blog/my-post.md with image named post-cover.png\nAdd the following to front-matter section content/blog/my-post.md\nimages: - post-cover.png Viewing html for post we can see \u0026quot;og:image\u0026quot; has been added to the meta data.\n\u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;http://blog.com/images/post/post-cover.png\u0026#34;\u0026gt; Note\rHugo uses the page title and description for the title and description metadata. The first 6 URLs from the images array are used for image metadata.\nOptional metadata can also be set:\nDate, published date, and last modified data are used to set the published time metadata audio and videos are URL arrays like images for the audio and video metadata tags First 6 tags on the page are used for the tags metadata Series taxonomy is used to specify related “see also” pages by placing them in the same series Summary This ia great way to adding usability outside of Hugo\u0026rsquo;s static web content. No click baiting please!\n","date":"January 1, 2023","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/tips/image_metadata/with/","title":"Hugo Share on LinkedIn Image Metadata"},{"categories":["hugo","web"],"contents":"Add a Last Modified Date in Hugo Articles Add date data to our Hugo posts\nLast Modified Last Updated Edited Conditionally render a Last Modified date in the single.html template for our posts.\nPublished {{ .Date.UTC.Format \u0026#34;Jan 2, 2006\u0026#34; }} Last Modified {{ .Lastmod.UTC.Format \u0026#34;Jan 2, 2006\u0026#34; }} Use Hugo’s date and lastmod fields.\nInfo\rWith multiple timezones need to normalize them by converting them all to UTC or all to our local timezone using UTC and Local.\rTwo ways we go about this:\n1. Automatically add lastmod field using Git metadata Automatically add the lastmod field to each article based on Git information.\nUpdate enableGitInfo in config.toml\nSet enableGitInfo to true in our config.toml.\nenableGitInfo = true The lastmod field will default to the most recent commit date for that file in Git.\nUpdate frontmatter in config.toml\nIf enableGitInfo is true, it will override any lastmod dates in front matter.\nBy default, :git comes before lastmod. To override add the following lines to the config file to config.toml\nenableGitInfo = true [frontmatter] date = [\u0026#34;date\u0026#34;, \u0026#34;publishDate\u0026#34;, \u0026#34;lastmod\u0026#34;] lastmod = [\u0026#34;lastmod\u0026#34;, \u0026#34;:git\u0026#34;, \u0026#34;date\u0026#34;, \u0026#34;publishDate\u0026#34;] publishDate = [\u0026#34;publishDate\u0026#34;, \u0026#34;date\u0026#34;] expiryDate = [\u0026#34;expiryDate\u0026#34;] Note\rThis approach is not recommended, since changes to a Git file may not always correlate to changes in the article content. It could simply be a minor style change or other changes that aren’t relevant to the content.\r2. Manually add lastmod to front matter Second approach is to manually add lastmod fields to front matter whenever an article is updated.\nWe want the Last Modified date to show only if we explicitly set it in the front matter.\nAdd lastmod to front matter\nAdd the lastmod field to our article front matter:\ndate: \u0026#34;2022-01-10\u0026#34; lastmod: \u0026#34;2022-01-15\u0026#34; Info\rIf enableGitInfo is true, lastmod will be set to the most recent commit date for that file and override any lastmod dates.\nCange this behavior by configuring front matter dates: [\u0026quot;lastmod\u0026quot;, \u0026quot;date\u0026quot;, \u0026quot;publishDate\u0026quot;]\nCreated a simple partial template This partial template checks if the lastmod and publish dates are the same then renders the dates. Compare two dates, Jan 2, 2006 is equal to mm.dd.yyyy.\nCreate lastmod.html\n{{ $date := .Date.UTC.Format \u0026#34;Jan 2, 2006\u0026#34; }} {{ $lastmod := .Lastmod.UTC.Format \u0026#34;Jan 2, 2006\u0026#34; }} \u0026lt;li class=\u0026#34;list-inline-item d-flex align-items-center\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fas fa-calendar me-2\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span\u0026gt;Published on {{ $date }}\u0026lt;/span\u0026gt; \u0026lt;li class=\u0026#34;list-inline-item d-flex align-items-center\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fas fa-calendar me-2\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; {{ if ne $lastmod $date }} \u0026lt;span\u0026gt; Edited on {{ $lastmod }}\u0026lt;/span\u0026gt; {{ end }} \u0026lt;/li\u0026gt; In single.html or post.html this can be called with the following {{ partial \u0026quot;lastmod.html\u0026quot; . }}\nSummary Minor update to improve information.\nCheck out the something interesting: Hugo Improve Usability ","date":"December 29, 2022","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/tips/lastmod-date/","title":"Add a Last Modified Date in Hugo Articles"},{"categories":["github","git"],"contents":"GIT OOPS! Question\rYep\u0026hellip; I have absolutely no idea what I meant by \u0026lsquo;Fix foobar\u0026rsquo; 6 months ago.\rTrying to write better commits fixed bug on landing page vs. fix: bug preventing users from submitting the subscribe form\nAssuming you already understand basic Git workflow. If not, I suggest reading through the Git Handbook.\nIt is also important to note that you should follow your team\u0026rsquo;s conventions\nThe Anatomy of a Commit Message Basic: git commit -m \u0026lt;message\u0026gt; Detailed:\ngit commit -m \u0026lt;title\u0026gt; -m \u0026lt;description\u0026gt; Tthoughtful commits, consider the following:\nWhy have I made these changes? What effect have my changes made? Why was the change needed? What are the changes in reference to? Assume the reader does not understand what the commit is addressing.\nMake clear why that change was made, and note if it is crucial for the functionality or not.\nExample:\ngit commit -m \u0026#39;Add wdiget\u0026#39; git commit -m \u0026#39;Add wdiget to nav items to prevent them from overlapping the logo\u0026#39; Tip\rVScode Git Blame extension adds git blame information to your vscode compatible view. Git historical information are Git History and GitLens.\rExample commit types:\nfeat – a new feature is introduced with the changes fix – a bug fix has occurred chore – changes that do not relate to a fix or feature and don\u0026rsquo;t modify src or test files (for example updating dependencies) refactor – refactored code that neither fixes a bug nor adds a feature docs – updates to documentation such as a the README or other markdown files style – changes that do not affect the meaning of the code, likely related to code formatting such as white-space, missing semi-colons, and so on. test – including new or correcting previous tests perf – performance improvements ci – continuous integration related build – changes that affect the build system or external dependencies revert – reverts a previous commit Full Conventional Commit Example fix: fix foo to enable bar This fixes the broken behavior of the component by doing xyz. BREAKING CHANGE Before this fix foo wasn\u0026#39;t enabled at all, behavior changes from \u0026lt;old\u0026gt; to \u0026lt;new\u0026gt; Closes XXXX-12345 Example conventions, it\u0026rsquo;s helpful to include guidelines for commits in a contributing or README markdown file within your projects.\nLearn more about Conventional Commit SemVer.org and here.\nCommit Message Comparisons Good feat: improve performance with lazy load for images chore: update python dependency to latest version fix: bug preventing users from submitting the subscribe form update: incorrect client phone number within footer body per client request Bad fixed bug on landing page Changed style oops I think I fixed it this time? empty commit messages Summary Writing good commit messages is an extremely beneficial skill, and it helps to communicate and collaborate. Commits serve as an archive of changes. Need to establish a set of agreed-upon standards that can be followed, but as long as your team agrees upon a convention.\n","date":"December 27, 2022","image":"https://devnall.io/images/post/git/gitops_hue1bc2a89d19a6f5e5f7372def848e8ce_44077_650x0_resize_box_3.png","permalink":"/blog/git/commit-msg/","title":"Write Better Commit Messages"},{"categories":["hugo","web"],"contents":"How to modify themes Hugo Use non-destructive practice for Hugo themes. Hugo is designed for customization and follows a site generation workflow that works a lot like layers in photo editing software.\nAdding a custom index.html file in the site layouts folder overrides the one in the theme folder. To change the index.html code without changing the theme code. Customizing the theme CSS styles requires leveraging the layouts folder override.\nTo modify the CSS take advantage of cascading. Here is an example:\nOverride the head.html file by copying the head.html file from the themes/\u0026lt;theme\u0026gt;/layouts/partials folder into a new folder in the site layouts/partials. This new head.html file now overrides the theme head.html. Add a link to the new override.css file. The code below shows the existing link to the style.css and the new override.css.\n{{ $style := resources.Get \u0026#34;scss/style.scss\u0026#34; | resources.ToCSS | minify }} \u0026lt;link href=\u0026#34;{{ $style.Permalink }}\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt; {{ $override := resources.Get \u0026#34;css/override.css\u0026#34; }} \u0026lt;link href=\u0026#34;{{ $override.Permalink }}\u0026#34; rel=\u0026#34;stylesheet\u0026#34;/\u0026gt; Summary Hugo themes are easy to add and swap, simply copy or pull the theme files to site\u0026rsquo;s themes folder and update the config.toml theme property to the name of the theme folder.\nThemes are tightly coupled to their data schemas, so do not expect to take a site with full content and swap the theme. Might need to port data to match the new data schema.\nHugo themes are easy to override and build upon without the need to directly change the theme files. The Hugo theme approach is simple yet powerful, it is one of the reasons Hugo is my preferred static site generator.\nCheck out the something interesting:\nHugo Adding Custom Notices ","date":"December 26, 2022","image":"https://devnall.io/images/post/hugo/theme-layout_huea4b75fdd8c7038788e21ce24f738933_123547_650x0_resize_q90_box.jpg","permalink":"/blog/hugo/tips/mod-theme/","title":"Modify Themes Hugo"},{"categories":["hugo","web"],"contents":"Hugo Adding Custom Notices Warning\rMight be batter way to complete this with out destroying theme.\rModify Themes Hugo How to modify themes for Hugo\nAdd these notices More Rich Content to current theme geeky_hugo. This might be different base on theme layout.\nIn the root of the themes directory navigate to themes/\u0026lt;name\u0026gt;/assets/scss\nCurrent theme has four files modification to add custom notices from coder.\nThe _notices.scss and notice.html need to be copied to current themes folder based on it\u0026rsquo;s layout. _variables.scss Only need coloring sections add. Finaly step is to import into @import 'notices.scss';\nFiles:\nassets/scss/_notices.scss assets/scss/_variables.scss layouts/shortcodes/notice.html assets/scss/style.scss File: _notices.scss\n... TRUNCATED OUTPUT ... .notice { border-radius: 0.2rem; position: relative; margin: 2rem 0; padding: 0 0.75rem; overflow: auto; .notice-content { display: block; margin: 2rem 2rem; } } .notice.note { background-color: $bg-color-notice-note-content; ... TRUNCATED OUTPUT ... File: _variables.scss\n// Notice colors $fg-color-notice-note-icon: #5e35b1 !default; $bg-color-notice-note-title: #673ab71a !default; $bg-color-notice-note-content: #7e57c21a !default; ... TRUNCATED OUTPUT ... $fg-color-notice-example-icon: #6d4c41 !default; $bg-color-notice-example-title: #7955481a !default; $bg-color-notice-example-content: #8d6e631a !default; ... TRUNCATED OUTPUT ... In the theme root directory add the following assets/scss/style.scss\nFile: style.scss\n@import \u0026#39;notices.scss\u0026#39;; Shortcodes Code From the root of Hugo layouts/shortcodes\nWarning\rThe shortcodes might not be created, so create it if required.\rUse the following code that can be referenced in markdown code.\nFile: notice.html\n{{- $type := .Get 0 -}} {{- $title := .Get 1 | default $type -}} {{- $inner := .Inner | .Page.RenderString | chomp -}} {{- $icon := dict \u0026#34;note\u0026#34; \u0026#34;fa-sticky-note\u0026#34; \u0026#34;tip\u0026#34; \u0026#34;fa-lightbulb-o\u0026#34; \u0026#34;example\u0026#34; \u0026#34;fa-file-text\u0026#34; \u0026#34;question\u0026#34; \u0026#34;fa-question\u0026#34; \u0026#34;info\u0026#34; \u0026#34;fa-exclamation-circle\u0026#34; \u0026#34;warning\u0026#34; \u0026#34;fa-exclamation-triangle\u0026#34; \u0026#34;error\u0026#34; \u0026#34;fa-times-circle\u0026#34; -}} \u0026lt;div class=\u0026#34;notice {{ $type }}\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;notice-title\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fa {{ index $icon $type }}\u0026#34; aria-hidden=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/i\u0026gt;{{ i18n $title | default $title | humanize }} \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;notice-content\u0026#34;\u0026gt; {{- $inner -}} \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Examples: Shortcodes Note\rOne note here.\rTip\rI\u0026rsquo;m giving a tip about something.\rExample\rThis is an example.\rQuestion\rIs this a question?\rInfo\rNotice that this box contain information.\rWarning\rThis is the last warning!\rError\rThere is an error in your code.\rSummary Hugo themes are easy to add and swap, simply copy or pull the theme files to site\u0026rsquo;s themes folder and update the config.toml theme property to the name of the theme folder.\nThemes are tightly coupled to their data schemas, so do not expect to take a site with full content and swap the theme. Might need to port data to match the new data schema.\nHugo themes are easy to override and build upon without the need to directly change the theme files. The Hugo theme approach is simple yet powerful, it is one of the reasons Hugo is my preferred static site generator.\nCheck out the something interesting:\nModify Themes Hugo How to modify themes for Hugo\n","date":"December 26, 2022","image":"https://devnall.io/images/post/hugo/custom_notices_hu99b68cc0ca4b1e2b886302b9869e8861_23558_650x0_resize_box_3.png","permalink":"/blog/hugo/tips/custom-notices/","title":"Hugo Adding Custom Notices"},{"categories":["hugo","web"],"contents":"Content Organization Trying to find a good way to organize content and this looks like this could be completed with Page Bundles.\nPage Bundles The illustration shows three bundles.\nNote: that the home page bundle cannot contain other content pages, although other files (images etc.) are allowed.\nWithout any additional configuration, the following will automatically work:\n. └── content └── about | └── index.md // \u0026lt;- https://example.com/about/ ├── posts | ├── firstpost.md // \u0026lt;- https://example.com/posts/firstpost/ | ├── happy | | └── ness.md // \u0026lt;- https://example.com/posts/happy/ness/ | └── secondpost.md // \u0026lt;- https://example.com/posts/secondpost/ └── quote ├── first.md // \u0026lt;- https://example.com/quote/first/ └── second.md // \u0026lt;- https://example.com/quote/second/ Summary Information presented here is based on Page Bundles. I will revision if errors or issues occur.\n","date":"December 24, 2022","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/tips/content-org/","title":"Hugo Content Organization"},{"categories":["hugo","web"],"contents":"Make Site More Informative Add Reading Time to current theme.\nAdd Reading Time to list Page Showing Reading Time is a great addition, by helping visitors to decide if the article is interesting enough to read..ReadingTime is a function of Hugo - which is calculated from the number of words in markdown content.\nAs this is a built in function, this can added.\nUpdate Theme This will vary based on theme and files might be different.\nOpen \u0026lt;theme\u0026gt;/layouts/_defaults/single.html \u0026lt;theme\u0026gt;/layouts/_defaults/post.html and add find author section in geeky-hugo theme location this in:\nAuthor and Publish Date are generated. Notice the \u0026lt;li\u0026gt; \u0026lt;/li\u0026gt; section.\n... TRUNCATED OUTPUT ... \u0026lt;ul class=\u0026#34;list-inline card-meta d-flex align-items-center mb-3\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;list-inline-item d-flex align-items-center\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fas fa-user me-2\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;a href=\u0026#34;{{`about` | relLangURL}}/\u0026#34;\u0026gt;{{site.Params.author}}\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;list-inline-item d-flex align-items-center\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fas fa-calendar me-2\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span\u0026gt;{{ time.Format \u0026#34;:date_long\u0026#34; .PublishDate }}\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ... TRUNCATED OUTPUT ... Add the following to include read time.\n\u0026lt;span class=\u0026#34;reading\u0026#34;\u0026gt;{{ .ReadingTime }} {{ cond (eq .ReadingTime 1) \u0026#34;minute\u0026#34; \u0026#34;minutes\u0026#34; }} read\u0026lt;/span\u0026gt; Completed code with clock icon added with \u0026lt;i class=\u0026quot;fas fa-clock\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; just lookup Font Awesome Icons\n\u0026lt;li class=\u0026#34;list-inline-item d-flex align-items-center\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fas fa-clock\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; \u0026lt;span class=\u0026#34;reading\u0026#34;\u0026gt;{{ .ReadingTime }} {{ cond (eq .ReadingTime 1) \u0026#34;minute\u0026#34; \u0026#34;minutes\u0026#34; }} read\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; Summary Minor update to improve information.\nCheck out the something interesting: Hugo running on Android Hugo running on Android static blog site sync with github\n","date":"December 24, 2022","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/tips/site-info/","title":"Hugo Improve Usability"},{"categories":["android","hugo"],"contents":"Hugo Running on Android Assumption turmux already installed.\nTermux on Android needs to be install. Use apt or pkg to install hugo.\nStep 1 Install Hugo apt install hugo Start server Will get the following:\nError\r.hugo_build.lock: function not implemented\rrun with --noBuildLock\nhugo server --noBuildLock\rStart building sites …\rhugo v0.109.0+extended android/arm64 BuildDate=unknown\r| EN\r-------------------+-----\rPages | 35\rPaginator pages | 0\rNon-page files | 6\rStatic files | 1\rProcessed images | 64\rAliases | 10\rSitemaps | 1\rCleaned | 0\rBuilt in 981 ms Step 2. Create New Posts Syntax to create a new post: hugo new posts/POST_NAME.md\nCreate a post called index.md hugo new posts/hugoandroid/index.md this creates a directory named posts\nStart writing in markdown and publish in HTML.\nSummary Now we can build with markdown on the go and publish on the fly. Future post setting up Android with necessary tools.\n","date":"December 24, 2022","image":"https://devnall.io/images/post/banner_android_hu409a039fcebec6844eeabc69385732bb_118729_650x0_resize_box_3.png","permalink":"/blog/hugo/android/","title":"Hugo running on Android"},{"categories":["vcode","markdown"],"contents":"VSCode Extensions for Markdown Recommend vscode Markdown extensions.\nMarkdown All in One Markdown All in One is a must one for editing Markdown. It contains Markdown preview, keyboard shortcuts, auto preview, and more\u0026hellip;.\nThe shortcuts will make editing Markdown much easy:\nPath completion:\nDictionary Completion Dictionary Completion extension tab complete words and hopefully reduce spelling errors:\nPaste Image Insert more screenshots to Markdown files. Paste Image helps save images with greenshot. This extension supports Mac/Windows/Linux.\nDraw.io Need to draw diagrams. Extension Draw.io Integration:\nKanbn Kanbn stores the kanban board and tasks inside repository as markdown files. Easy to view and edit tasks using any editor with the benefit Git\u0026rsquo;s version control and collaboration features project.\nmarkdownlint Avoid inconsistent formatting in markdown with rules to encourage standards and consistency for Markdown files.\nPrettier - Code formatter multi-language formatting tool, very good support for markdown\nMind Map Mind map integration\nCode Spell Checker A basic spell checker that works well with code and documents.\njoplin-vscode-plugin Joplin notes integration Web Clipper browser extension to Notes, Notebooks, Tags.. within VsCode.\nSummary Help speed up blogging experience by publishing in markdown then converting HTML with Hugo. Will update as find more useful vscode extensions.\n","date":"December 24, 2022","image":"https://devnall.io/images/post/vscode-md_hu51be5c20beaf80d9f3111e924a350f35_1055416_650x0_resize_box_3.png","permalink":"/blog/vscode/exten-markdown/","title":"VSCode Extensions for Markdown"},{"categories":["Linux","SSH"],"contents":"SSH Tunnel A reverse SSH tunnel allows a local service to be securely accessible by a remote connection.\nUnderstanding Reverse SSH Tunnels Service on local computer that is running on port 80. Want to access this service from a remote computer, but a firewall is in the way.\nSetup Host Type IP Address Description Internal 192.168.1.6 Internal IP address of the local service Public 159.223.180.93 public IP address of the remote server Reverse SSH Tunnel Example Confirm listening ports Local:\nLocal server running web server on port 80 and ssh on port 22.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 :::80 :::* LISTEN Remote:\nRemote client running SSH services\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN Establishing a reverse SSH tunnel:\nFrom the local server run the following command to establish a SSH tunnel:\nssh -N -R localhost:8888:192.168.1.6:80 root@159.223.180.93 -N is a flag to just forward ports and not execute remote commands -R is the reverse SSH tunnel flag that forwards remote connections to the local side localhost is the host on the remote server that will bind to the local service 8888 is the port that the remote server will listen on 192.168.1.6 is the internal IP address of the local service 80 is the port of the local service root is the SSH user of the remote server 159.223.180.93 is the public IP address of the remote server Confirm listening ports Local\nNote\rLocal host no change on listening services.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 :::80 :::* LISTEN Remote\nAfter executing the reverse SSH tunnel command, the local service at 192.168.1.6:80 will be accessible on the remote machine at localhost:8888.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:8888 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:8888 :::* LISTEN Shorthand Tip\rRemote command execution or pseudo terminal will be allocated for this connection.\nssh -R 8888:localhost:80 root@159.223.180.93 Change the port number for other services.\nInfo\rDon’t need to include localhost of the local machine because it is default Default SSH port is 22, so don’t need to specify this -N flag is optional. Functionality will be the same Summary Greate way to access service on local computer that is running on port 80 that is running behind a firewall to access this service from remote computer.\nCheck out: SSH Tunnel SSH Proxy ","date":"December 14, 2022","image":"https://devnall.io/images/post/linux/ssh/ssh_reverse_hub076a556219325752d3f0d64f6ea18a0_25348_650x0_resize_box_3.png","permalink":"/blog/linux/ssh/reverse/","title":"SSH Reverse Tunnel"},{"categories":["Linux","SSH"],"contents":"SSH Tunnel How to setup a basic SSH tunnel to access remote server resources that may be blocked by a firewall or simply inaccessible over the internet.\nUnderstanding SSH Tunnels Remote server that is running on port 80. Access this service from local computer, but a firewall is in the way.\nSetup Host Type IP Address Description Local localhost Remote 192.168.0.6 Internal IP address of the local service To bypass the firewall restrictions, send the remote service over the SSH port via a tunnel.\nSSH Tunnel Example Confirm listening ports Remote\nRemote server running web server on port 80 and ssh on port 22.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN Note\rLocal host is not listening for any services, so will not return anything.\rFrom the remote run the following command to establish a SSH tunnel:\n\u0026gt; ssh -N -L localhost:8888:localhost:80 root@192.168.0.93 -N is a flag to just forward ports and not execute remote commands -L forwards local connections to the remote side localhost is the host on the local machine that will bind to the remote service 8888 is the port that the local machine will listen on localhost is the internal IP address of the remote service 80 is the port of the remote service root is the SSH user of the remote server 192.168.0.93 is the public IP address of the remote server The remote service at localhost:80 will be accessible on the local machine at http://127.0.0.1:8888.\nInfo\rSSH can be assigned another port just add -p 2222 of the remote server.\rConfirm listening ports Local\nLocal is now established local connection port 8888 to remote system 192.168.0.93:80.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 127.0.0.1:8888 0.0.0.0:* LISTEN Shorthand Tip\rRemote command execution or pseudo terminal will be allocated for this connection.\n\u0026gt; ssh -L 8888:localhost:80 root@192.168.0.93 Change the port number for other services.\nInfo\rDon’t need to include localhost of the local machine because it is default Default SSH port is 22, so don’t need to specify this -N flag is optional. Functionality will be the same Question\rMight be able to trace tunnel through lsof. Need to explore more.\n\u0026gt; lsof -a -i -c \u0026#39;/^ssh$/\u0026#39; Summary Greate way to access remote services that are private and not exposed to the internt or that are running behind a firewall to access this service from local computer.\nCheck out: SSH Reverse Tunnel ","date":"December 14, 2022","image":"https://devnall.io/images/post/linux/ssh/ssh_tunnel_hu2149426542e31828b53872e1484bd54b_23744_650x0_resize_box_3.png","permalink":"/blog/linux/ssh/tunnel/","title":"SSH Tunnel"},{"categories":["Linux","SSH"],"contents":"SSH Proxy Tunnel Setup an SSH tunnel proxy server as an intermediary between a local computer and remote server that has an inaccessible resource or service.\nSetup Host Type IP Address Description Public 192.168.0.83 Public IP address of the local service Public 159.223.0.93 Public IP address of the remote server SSH Proxy Tunnel Example Send the remote service over the SSH port via a tunnel.\nConfirm listening ports Local:\nLocal host is not listening for any services, so will not return anything.\nPorxy\nPorxy server running ssh on port 22.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN Remote\nRemote server running web server on port 80 and ssh on port 22.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 :::80 :::* LISTEN From the local server run the following to establish a SSH proxy tunnel:\nssh -N -L localhost:8888:192.168.0.83:80 root@192.168.0.93\n-N is a flag to just forward ports and not execute remote commands -L forwards local connections to the remote side localhost is the host on the local machine that will bind to the remote service 8888 is the port that the local machine will listen on 192.168.0.83 is the public IP address of the remote service 80 is the port of the remote service root is the SSH user of the remote server 192.168.0.93 is the public IP address of the proxy server Local\nThe SSH tunnel is established for the service at 192.168.0.83:80 will be accessible on the local machine at localhost:8888 via the proxy server at 192.168.0.93.\n\u0026gt; netstat -ntl Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 127.0.0.1:8888 0.0.0.0:* LISTEN tcp6 0 0 ::1:8888 :::* LISTEN Shorthand Tip\rRemote command execution or pseudo terminal will be allocated for this connection.\nssh -L 8888:192.168.0.83:80 root@192.168.0.93 Change the port number for other services.\nInfo\rDon’t need to include localhost of the local machine because that is the default Default SSH port is 22, so don’t need to specify that either -N flag is optional. Functionality will be the same whether or not include it Summary Greate way to access service on local computer that is running on port 80 that is running behind a firewall to access this service from remote computer.\nCheck out: SSH Reverse Tunnel SSH Tunnel ","date":"December 14, 2022","image":"https://devnall.io/images/post/linux/ssh/ssh_proxy_huf50c1b51d0107a2acf4e4b081c551508_44622_650x0_resize_box_3.png","permalink":"/blog/linux/ssh/proxy/","title":"SSH Proxy"},{"categories":["web","hugo"],"contents":"Hugo Setup with git This blog content is generated with Hugo static site generator and integrated with GitHub Pages. This post will step cover publishing and pushing the newest content to GitHub Pages.\nSuggested reading Getting Started with Hugo: Learn more on GitHub. Complete documentation is available at Hugo Documentation.\nStep 1. Create Repositories on GitHub Assumptions already familiar with git commands and GitHub.\nCreate two repos\nName Access Purpose blog public Working local edits for changing adding content myblog.github.io public Syncing output of public folder to github or web server GitHub Pages There are two types of GitHub Pages:\nUser/Organization Pages https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/ Project Pages https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/\u0026lt;PROJECT\u0026gt;/ Step 2. Create New Site With hugo command create new site blog and change into the directory:\nhugo new site blog cd to blog Run initialize the directory as a git repository\ngit init Initialized empty Git repository... Add the github repository as a remote using git remote\nSubstitute \u0026lt;USERNAME\u0026gt; with your username.\ngit remote add origin https://github.com/\u0026lt;USERNAME\u0026gt;/blog.git git fetch --all git pull origin main At this point need to choose a them to continue.\nChoose themes Step 3. Installation theme Using the mainroad theme.\nFrom the project\u0026rsquo;s blog root directory, run:\ngit clone https://github.com/vimux/mainroad.git themes/mainroad\nNote\rIf not planning to making any significant changes but want to track and update the theme, add it as a git submodule via the following command:\rgit submodule add https://github.com/vimux/mainroad.git themes/mainroad Edit config.toml\nSpecify mainroad as default theme in the config.toml file.\ntheme = \u0026#34;mainroad\u0026#34; Change baseurl baseurl = \u0026quot;https://github.com/myblog-hub/myblog.github.io/\u0026quot; this is what will be pointing at the public part of the repo.\nInfo\rMake sure to end baseurl with a / and also confirm baseurl is set to Project Pages https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/\u0026lt;PROJECT\u0026gt;/ If any problems when publishing tweak until works.\rStep 5. Preview site locally From the project\u0026rsquo;s blog root directory, run:\nhugo server ... TRUNCATED OUTPUT ... Watching for config changes in C:\\..\\..\\blog\\myblog.github.io\\config.toml Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) ... TRUNCATED OUTPUT ... Open browser to http://localhost:1313\nStep 4. Create New Posts Syntax to create a new post: hugo new posts/POST_NAME.md\nCreate a post called mypost.md hugo new posts/mypost.md this creates a directory named posts\nInfo\rDepending on the theme this might need to be updated in the configuration config.toml as might be reference as post.\rStep 5. Production repo setup In production repo need to make sure have one commit and main branch if this was not already done through GitHub Page.\nIf README.md not added to remote repo then complete following or just add submodule\ngit clone https://github.com/\u0026lt;USERNAME\u0026gt;/myblog.github.io cd myblog.github.io git checkout -b main add README.md git add . git commit -m \u0026#34;adding readme.md\u0026#34; git push origin main Add Submodule From the project\u0026rsquo;s blog root directory add submodule, run:\ngit submodule add -b main https://github.com/\u0026lt;USERNAME\u0026gt;/myblog.github.io.git public Warning\rThis might fail due to running hugo server cammand, just delete the public folder it will get recreated.\rStep 6. Generate static files Run with the theme used mainroad\nhugo -t mainroad Confirm public dir has been created.\n. ├── archetypes ├── assets ├── config ├── config.toml ├── content ├── data ├── layouts ├── netlify.toml ├── **public** ├── resources ├── static └── themes Confirm remote repo has been added git remote -v:\ngit remote -v origin https://github.com/\u0026lt;USERNAME\u0026gt;/myblog.github.io.git (fetch) origin https://github.com/\u0026lt;USERNAME\u0026gt;/myblog.github.io.git (push) Commit changes to production repo:\ncd public git add . git commit -m \u0026#34;init commit\u0026#34; git push origin main Step 7. GitHub Pages From the https://github.com/\u0026lt;USERNAME\u0026gt;/myblog.github.io.git Settings page check Pages section and make sure Branch main /root is selected.\nCheck the actions page and can monitor the workflows deployment.\nIdeas Hosting on Azure Azure storage static Azure Pipelines Azure Container Registry Azure Container Registry Tasks Hosting on AWS Cloudflare Summary The setup is great now website under full source control, build it anytime and host it literally anywhere. That’s not the end of the story!\n","date":"December 24, 2021","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/initial-setup/","title":"Hugo Static Blog Site Github"},{"categories":["security","zeek","rita"],"contents":"How to use a Raspberry PI 4 as a Network Sensor with Zeek and Rita The original idea can be found at the following:\nModification to this setup can be found on my git repo: rita-zeek-rpi4\nIdeas based on How to use a Raspberry PI as a Network Sensor\nInspired by Bill Stearns How to use a Raspberry PI as a Network Sensor intial thoughts was that RITA will not run on RPi Rasbian OS as it appears to need MongoDB 64bit. Going to attempt to try to run Ubuntu 18.04 LTS RPi 4 Modle B 4GB.\nScope Run in headless mode No GUI assuming will save on resources Ubuntu Setup Installation Folow these steps: Install Ubuntu Server 20.04 LTS on Raspberry Pi 4 in Headless Mode and SSH Into It or these Install Ubuntu on Raspberry Pi\nDownload 18.04 server image ubuntu-18.04.5-preinstalled-server-arm64+raspi4.img.xz to substitute the others mentioned in the articales\nUpdates sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y\nERROR:\nE: Could not get lock /var/lib/dpkg/lock-frontend - open (11: Resource temporarily unavailable)\rE: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it? FIX ERROR:\nStop the automatic updater. sudo dpkg-reconfigure -plow unattended-upgrades At the first prompt, choose not to download and install updates. reboot\nMake sure any packages in an unclean state are installed correctly. sudo dpkg --configure -a\nGet your system up-top-date. sudo apt update \u0026amp;\u0026amp; sudo apt -f install \u0026amp;\u0026amp; sudo apt full-upgrade\nTurn the automatic updater back on or not. sudo dpkg-reconfigure -plow unattended-upgrades Select the package unattended-upgrades again.\nOR $ sudo fuser -v /var/lib/dpkg/lock-frontend USER PID ACCESS COMMAND /var/lib/dpkg/lock-frontend: root 2112 F.... unattended-upgr $ ps aux | grep 2112 root 2112 66.5 8.1 366108 113508 ? Sl 13:03 0:28 /usr/bin/python3 /usr/bin/unattended-upgrade --download-only $ dpkg -S /usr/bin/unattended-upgrade unattended-upgrades: /usr/bin/unattended-upgrade sudo kill -KILL 2112 sudo apt install -f sudo dpkg --configure -a sudo apt-purge unattended-upgrades Hostname sudo hostnamectl set-hostname urhostname\nsudo reboot now\nReferance: Ubuntu 18.04: Disable Netplan switch back to networking /etc/network/interfaces\nConfigure a network interface into promiscuous mode Note: On 18.04, we install networkd-dispatcher (see https://netplan.io/faq#use-pre-up-po...c-hook-scripts) which will allow you to run any further command you might need to finish the configuration of services / interfaces. That should allow you to make sure \u0026lsquo;ip link set ens192 promisc on\u0026rsquo; will persist across a reboot.\nSetup \u0026amp; Install ifupdown Install Install the ifupdown package and resolvconf\nsudo apt-get update sudo apt-get install -y ifupdown resolvconf Setup ifupdown Replace configuration files Delete all of the Netplan configuration files:\nsudo rm -rf /etc/netplan/*.yml or back it up until up and running cp /etc/netplan/50-cloud-init.yaml /etc/netplan/50-cloud-init.yaml.bak\nOpen the file /etc/network/interfaces and copy and paste the following:\n# The loopback network interface auto lo iface lo inet loopback # Mirror auto eth0 iface eth0 inet manual up ifconfig 0.0.0.0 up up ip link set eth0 promisc on down ip link set eth0 promisc off down ip link set eth0 down # Mgmt allow-hotplug eth1 auto eth1 iface eth1 inet static address 192.168.1.30 netmask 255.255.255.0 broadcast 192.168.1.255 gateway 192.168.1.1 dns-nameservers 192.168.1.1 8.8.8.8 source /etc/network/interfaces.d/*.cfg Setup resolv.conf Find out whether /etc/resolv.conf is a static file or symlink by the following command:\n$ ls -l /etc/resolv.conf /etc/resolv.conf -\u0026gt; ../run/resolvconf/stub-resolv.conf Need to remove the symlink between /etc/resolv.conf and stub-resolv.conf Issue the following command to change the symlink /etc/resolv.conf to point default dns server 192.168.1.1 instead of 127.0.0.53.\nsudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf ls -l /etc/resolv.conf Reboot\nreboot Promiscuous Mode Enable promiscuous mode:\nsudo ifconfig eth0 promisc Validate mode insabled:\nip -d link show eth0 2: eth0: mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 14:fe:b5:d5:51:9e brd ff:ff:ff:ff:ff:ff promiscuity 1 addrgenmode eui64 numtxqueues 8 numrxqueues 8 gso_max_size 65536 gso_max_segs 65535 promiscuity 1 means that the interface is in promiscuous mode promiscuity 0 means that the interface is not in promiscuous mode\nnetstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 26631 0 0 0 27143 0 0 0 BMPR Disable promiscuous mode\nsudo ifconfig eth0 -promisc sudo tail -f /var/log/syslog kernel: [ 2155.176013] device eth0 left promiscuous mode netstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 29172 0 0 0 29850 0 0 0 BMRU Enable /etc/rc.local on Systemd sudo systemctl status rc-local\nEnable /etc/rc.local Note: Starting with 16.10, Ubuntu doesn’t ship with /etc/rc.local file anymore. You can create the file by executing this command.\nYou may get this output:\n● rc-local.service - /etc/rc.local Compatibility Loaded: loaded (/lib/systemd/system/rc-local.service; static; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 2015-11-26 23:54:58 CST; 59s ago Process: 1001 ExecStart=/etc/rc.local start (code=exited, status=1/FAILURE) .... .... .... Output my very, but might not get anything.\nSolution create a file:\nsudo vim /etc/systemd/system/rc-local.service\nAdd content to it.\n[Unit] Description=/etc/rc.local Compatibility ConditionPathExists=/etc/rc.local [Service] Type=forking ExecStart=/etc/rc.local start TimeoutSec=0 StandardOutput=tty RemainAfterExit=yes SysVStartPriority=99 [Install] WantedBy=multi-user.target Run the following command to make sure /etc/rc.local file is executable.\nsudo chmod +x /etc/rc.local\nMight need to create /etc/rc.local create the file by executing this command.\nprintf \u0026#39;%s\\n\u0026#39; \u0026#39;#!/bin/bash\u0026#39; \u0026#39;exit 0\u0026#39; | sudo tee -a /etc/rc.local Execute permission to /etc/rc.local file.\nsudo chmod +x /etc/rc.local\nEnable the service on system boot:\nsudo systemctl enable rc-local\nOutput:\nCreated symlink from /etc/systemd/system/multi-user.target.wants/rc-local.service to /etc/systemd/system/rc-local.service. start the service and check its status:\nsudo systemctl start rc-local.service sudo systemctl status rc-local.service `` Output: ```sh ● rc-local.service - /etc/rc.local Compatibility Loaded: loaded (/etc/systemd/system/rc-local.service; enabled; vendor preset: enabled) Active: active (running) since Fri 2015-11-27 00:32:56 CST; 14min ago Process: 879 ExecStart=/etc/rc.local start (code=exited, status=0/SUCCESS) Main PID: 880 (watch) CGroup: /system.slice/rc-local.service Final output:\n#!/bin/bash\r#ethtool command to reduce processing at eth0\rethtool -K eth0 gro off rx off tx off gso off\rmkdir -p /opt/bro/pcaps\rscreen -S capture -t capture -d -m bash -c \u0026#34;nice -n 15 tcpdump -i eth0 -G 3600 -w \u0026#39;/opt/bro/pcaps/\u0026#39;`hostname -s`\u0026#39;.%Y%m%d%H%M%S.pcap\u0026#39; -z bzip2 \u0026#39;(tcp[13] \u0026amp; 0x17 != 0x10) or not tcp\u0026#39;\u0026#34;\rip link set eth0 promisc on\r/usr/local/zeek/bin/zeekctl start\rexit 0 Note: ethtool has a fixed parameter for large-receive-offload, so needed to edit this in the rc.local\nfixed parameter like large-receive-offload:\nsudo ethtool -K eth0 lro on Cannot change large-receive-offload Could not change any device features ethtool -k eth0 | grep large-receive-offload large-receive-offload: off [fixed] Referance: How to Enable /etc/rc.local with Systemd\nZeek IDS Installation on Raspberry PI Downloading and installing pre-requisites to Zeek from source\nsudo apt-get install cmake make gcc g++ flex bison libpcap-dev libssl-dev python-dev swig zlib1g-dev Addtional Packages\nsudo apt-get install libmaxminddb-dev postfix curl git Download and Install Zeek From git Source git clone --recursive https://github.com/zeek/zeek cd zeek ./configure make If everything goes right and no issues\nsudo make install Set the PATH\nexport PATH=/usr/local/zeek/bin:$PATH vim ~/.profile export PATH=/usr/local/zeek/bin:$PATH Setting up Zeek All the Zeek files should be installed in /usr/local/zeek\nEdit /usr/local/zeek/etc/node.cfg to set the interface to monitor; usually interface eth0\n[zeek] type=standalone host=localhost interface=eth0 Edit /usr/local/zeek/networks.cfg to add the IP addresses and short descriptions of your different routed networks. For example:\n10.0.0.0/8 Private IP space 172.16.0.0/12 Private IP space 192.168.0.0/16 Private IP space Edit /usr/local/zeek/etc/zeekctl.cfg and set the Edit /usr/local/zeek/etc/zeekctl.cfg and set the\nMailTo = blah@blah.com\nReplace to your email address to receive reports from your Zeek instance and set the LogRotationInterval to the log archiving frequency.\nStarting up Zeek Start the Zeek control shell with\nzeekctl\nOn the first time use – we need to do the initial installation\n[ZeekControl] \u0026gt; install Then to start the zeek process\n[ZeekControl] \u0026gt; start I also like using\n[ZeekControl] \u0026gt; deploy to refresh settings when starting\nTo stop the Zeek process\n[ZeekControl] \u0026gt; stop Other commands in zeekctl are available with the ? notation\nAlso check\n/usr/local/zeek/logs/current for the latest log files and\n/var/log/mail.log to troubleshoot Zeek e-mail reports to your e-mail address.\nAdd the following to /etc/rc.local file before the exit 0 line. IDS functionality is better with promiscuous mode on for the network interface. This will forward all packets to the CPU and not just the ones destined for the host.\nip link set eth0 promisc on /usr/local/zeek/bin/zeekctl start exit 0 Zeek needs to occasionally perform some scheduled maintenance:\ncrontab -e (select an editor and enter the following line) */5 * * * * /usr/local/zeek/bin/zeekctl Changing the log file format for better ingestion The best way for external software to ingest your zeek logs is to convert them to JSON format. In the original config, Zeek creates human readable text tables for each kind of log file created in /usr/local/zeek/logs/current such as:\ncat capture_loss.log #separator \\x09 #set_separator , #empty_field (empty) #unset_field - #path capture_loss #open 2019-08-31-02-04-06 #fields ts ts_delta peer gaps acks percent_lost #types time interval string count count double 1567213446.308621 900.000053 zeek 0 0 0.0 Edit /usr/local/zeek/share/zeek/site/local.zeek;\nAdd the following to the end of the file;\n#JSON Output @load policy/tuning/json-logs.zeek Save and close the site file; From the command-line restart zeek as the configuration has changed. zeekctl deploy Check to make sure your logs are now in JSON format.\ncat /usr/local/zeek/logs/current/packet_filter.log {\u0026#34;ts\u0026#34;:1567213927.478291,\u0026#34;node\u0026#34;:\u0026#34;zeek\u0026#34;,\u0026#34;filter\u0026#34;:\u0026#34;ip or not ip\u0026#34;,\u0026#34;init\u0026#34;:true,\u0026#34;success\u0026#34;:true} Referance: Zeek IDS Installation on Raspberry PI Part 1\nInstalling MongoDB to the Raspberry Pi 1. Upgrade all existing packages by running the command below. sudo apt update sudo apt upgrade 2. Install the MongoDB server from the Raspbian repository sudo apt install mongodb\n3. Start the MongoDB service. sudo systemctl enable mongodb sudo systemctl start mongodb Might get error about unable to resolve host (none)”\n/etc/hosts has an entry for localhost. It should have something like:\n127.0.0.1 localhost.localdomain localhost 127.0.1.1 my-machine 4. Run the following command to interact with the database by using the command line. mongo\nChecking the Mongo Service and Database 1. Check the status of our MongoDB server. sudo systemctl status mongodb\nResponse as we have shown below.\n● mongodb.service - An object/document-oriented database Loaded: loaded (/lib/systemd/system/mongodb.service; enabled; vendor Active: active (running) since Thu 2021-02-18 01:22:45 UTC; 1h 34min Docs: man:mongod(1) Main PID: 2066 (mongod) Tasks: 23 (limit: 4443) CGroup: /system.slice/mongodb.service └─2066 /usr/bin/mongod --unixSocketPrefix=/run/mongodb --con 2. Check the status of Mongo itself by retrieving its connection status. mongo --eval \u0026#39;db.runCommand({ connectionStatus: 1 })\u0026#39; MongoDB shell version v3.6.3 connecting to: mongodb://127.0.0.1:27017 MongoDB server version: 3.6.3 { \u0026#34;authInfo\u0026#34; : { \u0026#34;authenticatedUsers\u0026#34; : [ ], \u0026#34;authenticatedUserRoles\u0026#34; : [ ] }, \u0026#34;ok\u0026#34; : 1 } Referance: Installing MongoDB to the Raspberry Pi\ninstall Golang (Go) on Raspberry Pi Current stable version available at Golang official website is v1.16 and there is a distribution packaged for ARMv8 CPU go1.16.linux-arm64.tar.gz\nwget https://golang.org/dl/go1.16.linux-arm64.tar.gz\nsudo tar -C /usr/local -xzf o1.16.linux-arm64.tar.g rm go1.12.6.linux-armv6l.tar.gz Set PATH environment variable Golang is installed. To do that, edit the ~/.profile file:\nScroll all the way down to the end of the file and add the following:\nvim ~/.profile PATH=$PATH:/usr/local/go/bin GOPATH=$HOME/golang Re-load profile\nsource ~/.profile\nwhich go to find out where the Golang installed and go version to see the installed version and platform.\nwhich go /usr/local/go/bin/go go version go version go1.12.6 linux/arm Referance: install Golang (Go) on Raspberry Pi\nBuilding RITA Aa root build RITA from source code see addtional setps here or summary below.\ngit clone https://github.com/activecm/rita.git cd rita make make install to install the binary to /usr/local/bin/rita Configuring the system RITA requires some directories to be created for it to function correctly.\nsudo mkdir /etc/rita \u0026amp;\u0026amp; sudo chmod 755 /etc/rita sudo mkdir -p /var/lib/rita/logs \u0026amp;\u0026amp; sudo chmod -R 755 /var/lib/rita\nCopy config file RITA source code dir.\nsudo cp etc/rita.yaml /etc/rita/config.yaml \u0026amp;\u0026amp; sudo chmod 666 /etc/rita/config.yaml\n**Test ** using the rita test-config\nUserConfig: UpdateCheckFrequency: 14 MongoDB: ConnectionString: mongodb://localhost:27017 AuthenticationMechanism: \u0026#34;\u0026#34; SocketTimeout: 2h0m0s TLS: Enable: false VerifyCertificate: false CAFile: \u0026#34;\u0026#34; MetaDB: MetaDatabase Rolling: DefaultChunks: 24 rolling: false currentchunk: 0 ....... ....... ....... Summary Great way to monitor local area network with network tap on the cheap!!!\n","date":"February 19, 2021","image":"https://devnall.io/images/post/rpi/ripiinetsensor_hu054a3067d2fb9fc006b21a51c8f0033d_2488225_650x0_resize_box_3.png","permalink":"/blog/sec/rita-zeek-rpi4/","title":"How to use a Raspberry PI 4 as a Network Sensor with Zeek and Rita"},{"categories":["hugo","web"],"contents":"Hugo static HTML and CSS website generator Hugo is a static HTML and CSS website generator written in Go and edited in markdown. It is optimized for speed, ease of use, and configurability. Hugo takes a directory with content and templates and renders them into a full HTML website. With its amazing speed and flexibility, Hugo makes building websites fun again.\nLearn more on GitHub. Complete documentation is available at Hugo Documentation.\nStep 1. Install Hugo Go to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs Hugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\nClone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313 Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo cd hugo /path/to/where/you/installed/hugo server --source=./docs \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Press ctrl+c to stop Once you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site Stop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content \u0026gt; Press ctrl+c to stop Open your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 26 ms Refresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building.\nHaving nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun The best way to learn something is to play with it.\n","date":"January 24, 2021","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/blog/hugo/getting-started/","title":"Getting Started with Hugo"},{"categories":null,"contents":"","date":"January 1, 1","image":"https://devnall.io/images/post/hugo-logo_hu5ff7678116e37e4148cba01ab439f068_13782_650x0_resize_box_3.png","permalink":"/bak.archives/","title":""},{"categories":null,"contents":"This blog is brought to you by an Infrastructure IT Consultant. The goal of this content is to create easy to understand posts about creating complicated projects so anyone can follow them like a recipe and to help capture my ideas and thoughts.\nI architect, implement, administer and troubleshoot servers, network, storage and infrastructure devices local and cloud-based with an interest in DevSecOps. I write about things I am familiar with, things I am learning, and the things that I have had to understand in order to help others understand.\nFor more details on work experience, certifications and such, check LinkedIn. I tend to update that more frequently than this page.\nMy Skills GitHub Stats About Hugo This site was generated with markdown syntax and published with Hugo.\nHugo is a static HTML and CSS website generator written in Go and edited in markdown. It is optimized for speed, ease of use, and configurability. Hugo takes a directory with content and templates and renders them into a full HTML website. Hugo makes building websites fun again. 🤪\nLearn more on GitHub. Complete documentation is available at Hugo Documentation.\nSite Information\rSite generated on:\rTue, 24 Jan 2023 05:38:50 PT\rHugo\rversion:\r0.108.0\rPages generated:\r31\rCategories generated:\r20\rMonth generated:\r4\rSeries generated:\r8\rTags generated:\r40\rYears generated:\r0\r","date":"January 1, 1","image":"https://devnall.io/images/author_huea9d061bd187427311552ec59e0cb48b_679442_650x0_resize_box_3.png","permalink":"/about/","title":"About The Author"},{"categories":null,"contents":"","date":"January 1, 1","image":"https://devnall.io/images/author_huea9d061bd187427311552ec59e0cb48b_679442_650x0_resize_box_3.png","permalink":"/contact/","title":"Let's, Talk About You"},{"categories":null,"contents":"devnall.io Privacy Policy devnall.io is a privately owned and operated site run by me.\nMe/I (“us”, “we”, or “our”) operates the devnall website at https://devnall.io (hereinafter referred to as the “Service”).\nThis page informs you of our policies regarding the collection, use and disclosure of personal data when you use our Service and the choices you have associated with that data.\nWe use your data to provide and improve the Service. By using the Service, you agree to the collection and use of information in accordance with this policy.\nConsent By using our website, you hereby consent to our Privacy Policy and agree to its terms.\nComments Comments are disabled to avoid collecting any Personally Identifiable Information. Please feel free to reach out to me, or the guest author, on GitHub if you have any feedback.\nHow we use your information We use the information we collect in various ways, including to:\nProvide, operate, and maintain our website Improve, personalize, and expand our website Understand and analyze how you use our website Develop new products, services, features, and functionality Communicate with you, either directly or through one of our partners, including for customer service, to provide you with updates and other information relating to the website, and for marketing and promotional purposes Send you emails Find and prevent fraud Embedded content from other websites Articles on this site may include embedded content (e.g. videos, images, articles, etc.). Embedded content from other websites behaves in the exact same way as if the visitor has visited the other website.\nThese websites may collect data about you, use cookies, embed additional third-party tracking, and monitor your interaction with that embedded content, including tracking your interaction with the embedded content if you have an account and are logged in to that website.\nAds Advertisements on devnall.io are paid for in full by the advertisers. This does not in any way, shape or form, constitute an endorsement of a given company or product. It is an advertisement, treat it as such.\nSome of the ads displayed on devnall.io contain a tracking code, in order for the advertiser to track where link clicks originate. devnall.io does not send any Personally Identifiable Information to any advertisers.\nNo other data is sent to any other 3rd party.\nHow long we retain your data You have the right to know how long we retain your data, and we cannot hold your data indefinitely. We do not retain any Personally Identifiable Information, so that part is pretty easy.\nLog Files devnall.io follows a standard procedure of using log files. These files log visitors when they visit websites. All hosting companies do this and a part of hosting services\u0026rsquo; analytics. The information collected by log files include internet protocol (IP) addresses, browser type, Internet Service Provider (ISP), date and time stamp, referring/exit pages, and possibly the number of clicks. These are not linked to any information that is personally identifiable. The purpose of the information is for analyzing trends, administering the site, tracking users\u0026rsquo; movement on the website, and gathering demographic information.\nCookies and Web Beacons Like any other website, devnall.io uses ‘cookies\u0026rsquo;. These cookies are used to store information including visitors\u0026rsquo; preferences, and the pages on the website that the visitor accessed or visited. The information is used to optimize the users\u0026rsquo; experience by customizing our web page content based on visitors\u0026rsquo; browser type and/or other information.\nDoubleClick DART Cookie Google is one of a third-party vendor on our site. It also uses cookies, known as DART cookies, to serve ads to our site visitors based upon their visit to other sites on the internet. However, visitors may choose to decline the use of DART cookies by visiting the Google ad and content network Privacy Policy at the following URL – https://policies.google.com/technologies/ads.\nSome of advertisers on our site may use cookies and web beacons. Our advertising partners are listed below. Each of our advertising partners has their own Privacy Policy for their policies on user data. For easier access, we hyperlinked to their Privacy Policies below.\nGoogle https://policies.google.com/technologies/ads\nAdvertising Partners Privacy Policies You may consult this list to find the Privacy Policy for each of the advertising partners of devnall.io.\nThird-party ad servers or ad networks uses technologies like cookies, JavaScript, or Web Beacons that are used in their respective advertisements and links that appear on devnall.io, which are sent directly to users\u0026rsquo; browser. They automatically receive your IP address when this occurs. These technologies are used to measure the effectiveness of their advertising campaigns and/or to personalize the advertising content that you see on websites that you visit.\nNote that devnall.io has no access to or control over these cookies that are used by third-party advertisers.\nThird-Party Privacy Policies https://devnall.io Privacy Policy does not apply to other advertisers or websites. Thus, we are advising you to consult the respective Privacy Policies of these third-party ad servers for more detailed information. It may include their practices and instructions about how to opt-out of certain options. You may find a complete list of these Privacy Policies and their links here: Privacy Policy Links.\nYou can choose to disable cookies through your individual browser options. To know more detailed information about cookie management with specific web browsers, it can be found at the browsers\u0026rsquo; respective websites. What Are Cookies?\nChildren’s Information Another part of our priority is adding protection for children while using the internet. We encourage parents and guardians to observe, participate in, and/or monitor and guide their online activity.\ndevnall.io does not knowingly collect any Personal Identifiable Information from children under the age of 13. If you think that your child provided this kind of information on our website, we strongly encourage you to contact us immediately and we will do our best efforts to promptly remove such information from our records.\nChanges to This Privacy Policy We may update our Privacy Policy from time to time. You are advised to review this Privacy Policy periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n","date":"January 1, 1","image":"https://devnall.io/images/author_huea9d061bd187427311552ec59e0cb48b_679442_650x0_resize_box_3.png","permalink":"/privacy-policy/","title":"Privacy Policy"},{"categories":null,"contents":"","date":"January 1, 1","image":"https://devnall.io/images/author_huea9d061bd187427311552ec59e0cb48b_679442_650x0_resize_box_3.png","permalink":"/search/","title":"Search Result"}]